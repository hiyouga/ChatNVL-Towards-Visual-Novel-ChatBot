# 5 月 10 日实验日志

作者：hiyouga

数据集：koikake_yui_desc, koikake_yui_train

实验环境：A100 * 1

---

前些天看了 B 站的几个微调案例视频（[BV1gN411N7uE](https://www.bilibili.com/video/BV1gN411N7uE/)、[BV1PP411m7nD](https://www.bilibili.com/video/BV1PP411m7nD/)），猜想 prompt 对微调还是比较有用的，所以我试着在微调时候加入 prompt 来缓解 domain shift 问题。微调方法依旧选用 LoRA，微调所有层的 QKV 矩阵。之前的模型编辑论文 [ROME](https://rome.baulab.info/) 揭示了语言模型**中间层**的重要作用，所以不能仅微调后几层的参数。

```bash
CUDA_VISIBLE_DEVICES=0 python ~/chatglm_tuning/src/finetune.py \
    --do_train \
    --model_name_or_path ~/.cache/huggingface/hub/models--THUDM--chatglm-6b/snapshots/a8ede826cf1b62bd3c78bdfb3625c7c5d2048fbd \
    --dataset koikake_yui_desc,koikake_yui_train \
    --dataset_dir ../data \
    --finetuning_type lora \
    --output_dir yui_230510_lora_qkv \
    --overwrite_cache \
    --per_device_train_batch_size 4 \
    --gradient_accumulation_steps 4 \
    --lr_scheduler_type cosine \
    --logging_steps 10 \
    --save_steps 1000 \
    --learning_rate 5e-5 \
    --weight_decay 1e-5 \
    --num_train_epochs 5.0 \
    --lora_target query_key_value \
    --source_prefix 现在你将扮演结衣，模拟学长和结衣的对话。结衣，你是御影浜学校的少女，喜欢学长、绘本、安静的地方、花和小动物。请根据角色性格特点，补全对话，下面是对话片段。 \
    --plot_loss \
    --fp16
```

![1.jpg](media/230510_1.jpg)

优化 step 只有不到 250 步，不足以训练到收敛。同时训练集也不够大，没有利用其他人物的对话。在测试时，模型的对话偏向于给出很短的回复。

![2.jpg](media/230510_2.jpg)

同时不加前缀时，模型并不会进入角色，这或许是一种好现象。

![3.jpg](media/230510_3.jpg)

先试着增加训练轮数，使其能训练 5000 步左右。

```bash
CUDA_VISIBLE_DEVICES=0 python ~/chatglm_tuning/src/finetune.py \
    --do_train \
    --model_name_or_path ~/.cache/huggingface/hub/models--THUDM--chatglm-6b/snapshots/a8ede826cf1b62bd3c78bdfb3625c7c5d2048fbd \
    --dataset koikake_yui_desc,koikake_yui_train \
    --dataset_dir ../data \
    --finetuning_type lora \
    --output_dir yui_230510_lora_qkv_100r \
    --overwrite_cache \
    --per_device_train_batch_size 4 \
    --gradient_accumulation_steps 4 \
    --lr_scheduler_type cosine \
    --logging_steps 10 \
    --save_steps 1000 \
    --learning_rate 5e-5 \
    --weight_decay 1e-5 \
    --num_train_epochs 100.0 \
    --lora_target query_key_value \
    --source_prefix 现在你将扮演结衣，模拟学长和结衣的对话。结衣，你是御影浜学校的少女，喜欢学长、绘本、安静的地方、花和小动物。请根据角色性格特点，补全对话，下面是对话片段。 \
    --plot_loss \
    --fp16
```

在大概 3000 步的时候，loss 已经下降到几乎为 0，说明模型可以完全拟合该数据集。

![4.jpg](media/230510_4.jpg)

测试了几组对话，有时候还是比较流畅的，并且一定程度上学习到了原人物的说话风格。

![5.jpg](media/230510_5.jpg)

使用微调前的模型做测试，虽然前后连贯性比微调后的模型更好，但是对话风格没有微调后的模型更有个性。

![6.jpg](media/230510_6.jpg)

---

这次实验通过增加微调轮数和添加 prompt 的方式，实现了初步的人物对话风格模拟。之后的目标主要在于以下几点：

- 在监督微调（SFT）阶段使用指令数据集，确保模型的回答有因果性。
- 使用 RLHF 技术训练微调后的模型，提高模型的回答质量。
- 进一步探索 prompt 在微调阶段的意义。
